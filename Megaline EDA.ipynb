{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which one is a better plan?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project remains to analyze the data provided by the telecom operator Megaline. With an offering of two plans, Surf and Ultimate, the goal of this project is to determine optimal capital allocation. We will determine which plan brings in more revenue. This will result in an adjustment of the advertising budget, as a means to further increase revenue. The dataset provided is a sample of the population of Megaline customers, across different cities in 2018. We will conduct further analysis on the client behavior, as well as look at other important insights found in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thoughts suggest the Surf plan would bring in more revenue, as the overage charges, combined with the limited plan allotment, would lead to many customers paying fees. The Ultimate plan is more than double the price of the Surf plan, and the company lacks and middle tier plan. As a result, we hypothesize that the Surf plan would be far more popular than the Ultimate plan, further contributing to the differences in revenue. Yet another factor could be the overages charges on the Ultimate plan, as they are far lower than those of the Surf plan. We expect to see differences in plan preference based on age, as well as revenue when looking across age groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load useful libraries that will aid us in evaluating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/megaline_calls.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data files into different DataFrames\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_calls \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/datasets/megaline_calls.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df_int \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/megaline_internet.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_msg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/megaline_messages.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/megaline_calls.csv'"
     ]
    }
   ],
   "source": [
    "# Load the data files into different DataFrames\n",
    "df_calls = pd.read_csv('/datasets/megaline_calls.csv')\n",
    "df_int = pd.read_csv('/datasets/megaline_internet.csv')\n",
    "df_msg = pd.read_csv('/datasets/megaline_messages.csv')\n",
    "df_plans = pd.read_csv('/datasets/megaline_plans.csv')\n",
    "df_users = pd.read_csv('/datasets/megaline_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display files to have a visual of the data\n",
    "display(df_calls)\n",
    "display(df_int)\n",
    "display(df_msg)\n",
    "display(df_plans)\n",
    "display(df_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Thoughts \n",
    "\n",
    "Looking at the data we see all the information needed to calculate total revenue of the two plans. However, several dataframes would need to be merged, grouped, and appended with summary columns. The user ID column appears in many tables, so that can be the key to merging the different dataframes. We would also need to categorize the data by the specific plans: Surf and Unlimited. The call, message, and session dates can be used to append the data tables with a column that specifies the month. Then, we can categorize data by month to month. Analyzing the data based on a year would me a logical fallacy, as fluctuations in usage are expected on a monthly basis. In other words, some users may exceed their plan some months, and be charged fees, while also under use their allotment another month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be explored to determine the need for removing duplicates, missing values, or unnecessary columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the general/summary information about the plans' DataFrame\n",
    "df_plans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a sample of data for plans\n",
    "display(df_plans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset that provides the variables for the two plans. We will use this data to calculate the monthly cost per customer, including overages charged to the customer. No missing values are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fix obvious issues with the data given the initial observations.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at column names\n",
    "df_plans.columns = ['messages_included', 'mb_per_month_included', 'minutes_included',\n",
    "       'usd_monthly_pay', 'usd_per_gb', 'usd_per_message', 'usd_per_minute',\n",
    "       'plan']\n",
    "df_plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing needs to be fixed continue to the next dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the general/summary information about the users' DataFrame\n",
    "df_users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two date columns are not in the date/time format. We need to change at least the reg date to extract data from the column. We are less concerned with churn date at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df_users.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking at unique values\n",
    "df_users.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Quick overview of tables and values\n",
    "df_users.describe(include='all',datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice all user ID's are unique, so there are no duplicates in the data. Although there are only 458 unique first names, we expect some people could have the same name. This also applies to last names. We see this data is distributed among 73 cities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Users who cancelled their plans \n",
    "df_users.groupby('user_id')['churn_date'].value_counts().nlargest(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for users\n",
    "display(df_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes customers, their location, registration date, plan, and churn date. We have missing values in the churn date column we do not need to fix. We could set the missing values to 'active', to denote the plans are still active, yet that will convert the column data type. However, we need to change reg date to date/time format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert churn date column format to date/time\n",
    "df_users['churn_date'] = pd.to_datetime(df_users['churn_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reg date column format to date/time \n",
    "df_users['reg_date'] = pd.to_datetime(df_users['reg_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confirm type change\n",
    "df_users.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not changing value to active, as this will change the column type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at users dataframe\n",
    "display(df_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not need to delete data based on churn date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a month start column \n",
    "df_users['month_start'] = df_users['reg_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check proper implementation\n",
    "display(df_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added the month start colum for ease in merging data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the general/summary information about the calls' DataFrame\n",
    "df_calls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a sample of data for calls\n",
    "display(df_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values per column\n",
    "df_calls.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick summary of data in columns\n",
    "df_calls.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls data is complete with no missing values. We are not concerned with duplicates. The call date column should be changed to date/time format. We would also need to extract the month from the date, and categorize our values by user id and month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing call date colum format to date/time\n",
    "df_calls['call_date'] = pd.to_datetime(df_calls['call_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for proper implementation\n",
    "df_calls.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a month column \n",
    "df_calls['month'] = df_calls['call_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for proper implementation\n",
    "display(df_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group data by user ID and month, then take the sum of the call duration\n",
    "df_calls_mo = df_calls.groupby(['user_id','month'])['duration'].sum()\n",
    "display(df_calls_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pivot table illustrating call duration\n",
    "df_calls_pivot = df_calls.pivot_table(index='user_id',\n",
    "                            columns='month',\n",
    "                            values='duration',\n",
    "                            aggfunc='sum'\n",
    "                                     )\n",
    "display(df_calls_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We changed the call date colum to the date/time type, and extracted the month to create a column that distinguishes the months of the data. We notice some missing values in the data, but we will keep them. It is not unusual for some months to have no data, as users could start in different months. Users could also not make any calls in a particular month, which is less likely, but still a possibility. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the general/summary information about the messages' DataFrame\n",
    "df_msg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for messages\n",
    "display(df_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Quick overview of the data in user ID column\n",
    "df_msg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message dataframe has a message date column that needs to be changed to date/time format. We do not see missing values, and are not concerned with duplicates. We would need to extract the month from the message day, group by user id, and count the number of messages for that month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column message date format to date/time\n",
    "df_msg['message_date'] = pd.to_datetime(df_msg['message_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper implementation\n",
    "df_msg.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a month column from message date\n",
    "df_msg['month'] = df_msg['message_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visual of new column, month\n",
    "display(df_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grouping data by user ID and month, then counting the number of times a message was sent in that month\n",
    "df_msg_mo = df_msg.groupby(['user_id','month'])['message_date'].count().reset_index() \n",
    "df_msg_mo.columns = ['user_id', 'month', 'message_count']\n",
    "display(df_msg_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pivot table showing the number of messages\n",
    "df_msg_pivot = df_msg.pivot_table(index='user_id',\n",
    "                            columns='month',\n",
    "                            aggfunc='count'\n",
    "                                     )\n",
    "display(df_msg_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing values, as expected, due to people starting their plans in different months. We will not fill in the missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the general/summary information about the internet DataFrame\n",
    "df_int.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of data for the internet traffic\n",
    "display(df_int.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internet data does not contain missing values, and we are not concerned with duplicates. We would need to perform similar strategies with the previous tables. We should extract the month, and organize the mb used by user id and month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert session date format to date/time\n",
    "df_int['session_date'] = pd.to_datetime(df_int['session_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check proper implementation\n",
    "df_int.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted session date to date/time format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a month column from session date\n",
    "df_int['month'] = df_int['session_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check proper implementation\n",
    "display(df_int.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added a month column to group data based on month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grouped the data based on user ID and month, then took the sum of the data used \n",
    "df_int_mo = df_int.groupby(['user_id', 'month'])['mb_used'].sum()\n",
    "display(df_int_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pivot table of data used per month\n",
    "df_int_pivot = df_int.pivot_table(index='user_id',\n",
    "                            columns='month',\n",
    "                            values='mb_used',\n",
    "                            aggfunc='sum'\n",
    "                                     )\n",
    "display(df_int_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot table groups data by user id and month, then sums the data used in megabytes. We will keep the missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study plan conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print out the plan conditions\n",
    "df_plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two plans: Surf and Ultimate. Surf costs 20 dollars per month, and includes overage fees. The ultimate plan is 70 dollars per month and also includes overage fees, but they are less than that of Surf. Data included in the plans is in megabytes, yet the cost is in gigabytes. We will use the conversion factor of 1 gb = 1024 mb. We note that the currency is US dollars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data per user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of calls made by each user per month. Save the result.\n",
    "\n",
    "df_calls_num = df_calls.groupby(['user_id','month'])['duration'].count().reset_index()\n",
    "df_calls_num.columns = ['user_id', 'month', 'calls']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df_calls_mo.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df_msg = df_msg.loc[:,'user_id':]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of messages sent by each user per month. Save the result.\n",
    "df_msg_mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the volume of internet traffic used by each user per month. Save the result.\n",
    "df_int_mo.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the data for calls, minutes, messages, internet based on user_id and month\n",
    "df_1 = df_calls_num.merge(df_calls_mo, on=('user_id', 'month'), how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Appending data column\n",
    "df_2 = df_1.merge(df_int_mo, on=('user_id', 'month'), how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending number of messages column \n",
    "df_3= df_2.merge(df_msg_mo, on=('user_id', 'month'), how='outer')\n",
    "df_3.columns = ['user_id', 'month', 'num_calls', 'call_duration', 'mb_used', 'num_messages']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User ID and plan table \n",
    "df_user_plan = df_users[['user_id', 'plan']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add the plan information, merge on user ID\n",
    "df_4 = df_3.merge(df_user_plan, on='user_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual of plans table\n",
    "df_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merging for final dataset\n",
    "df_merged = df_4.merge(df_plans, on='plan', how='outer')\n",
    "df_merged = df_merged.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Calculate the monthly revenue from each user (subtract the free package limit from the total number of calls, text messages, and data; multiply the result by the calling plan value; add the monthly charge depending on the calling plan).]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to round up minutes, gb data\n",
    "def round_up(n, decimals=0):\n",
    "    multiplier = 10 ** decimals\n",
    "    return mt.ceil(n * multiplier) / multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking functionality of round function\n",
    "round_up(31.366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the monthly revenue for each user\n",
    "# using megabytes instead of gigabytes, converted cost to appropriate value\n",
    "\n",
    "def revenue(row) :\n",
    "    \n",
    "    additional_mins = 0                      # to add additional minutes\n",
    "    additional_messages = 0                  # to add additional messages\n",
    "    additional_gb = 0                        # to add additional data\n",
    "    surf = 20                                # base price of Surf plan\n",
    "    ultimate = 70                            # base price of Ultimate Plan\n",
    "    \n",
    "    plan = row['plan']                       # looking at the plan row\n",
    "    call = round_up(row['call_duration'])    # rounding the call duration to the nearest minute\n",
    "    gb = round_up(row['mb_used'] / 1024)     # rounding the data to the nearest gigabyte\n",
    "    \n",
    "    \n",
    "    if plan == 'surf' :\n",
    "        if call > 500 :                      \n",
    "            additional_mins = call - 500\n",
    "        if row['num_messages'] > 50 :\n",
    "            additional_messages = row['num_messages'] - 50\n",
    "        if gb > 15 :\n",
    "            additional_gb = gb - 15\n",
    "        profit = (additional_mins * 0.03) + (additional_messages * 0.03) + (additional_gb * 10 )\n",
    "        if profit == 0 :\n",
    "            return surf\n",
    "        else :\n",
    "            return profit + surf\n",
    "\n",
    "        \n",
    "    if plan == 'ultimate' :\n",
    "        if call > 3000 :\n",
    "            additional_mins = call - 3000\n",
    "        if row['num_messages'] > 1000 :\n",
    "            additional_messages = row['num_messages'] - 1000      \n",
    "        if gb > 30 :\n",
    "            additional_gb = gb - 30\n",
    "        profit = (additional_mins * 0.01) + (additional_messages * 0.01) + (additional_gb * 7 )\n",
    "        if profit == 0 :\n",
    "            return ultimate\n",
    "        else :\n",
    "            return profit + ultimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study User Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will calculate some useful descriptive statistics for the aggregated and merged data, to reveal an overall picture captured by the data. We will display useful plots to help with the understanding of the given data. Given that the main task is to compare the plans and decide on which one is more profitable, the statistics and the plots will be calculated on a per-plan, and on a per month basis. Insights will be given on the relationships of the data among the various parameters, including age and location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare average duration of calls per each plan per each distinct month. Plot a bar plat to visualize it.\n",
    "df_merged_calls = df_merged.groupby(['plan', 'month'])['call_duration'].mean()\n",
    "display(df_merged_calls.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separated calls on Surf plan\n",
    "df_surf_calls = df_merged_calls[1:13].reset_index('plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separated calls on Ultimate plan\n",
    "df_ultimate_calls = df_merged_calls.reset_index('plan').tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged Surf and Ultimate call plans side by side\n",
    "df_all_calls = df_surf_calls.merge(df_ultimate_calls, on='month', how='outer')\n",
    "df_all_calls.columns = ['plan_s', 'surf', 'plan_u', 'ultimate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot call duration on Surf and Ultimate plans, by month\n",
    "df_all_calls.plot(kind='bar',\n",
    "                    title='Average Call Duration',\n",
    "                  xlabel='Month',\n",
    "                  ylabel='Average Call Duration',\n",
    "                  color=('blue', 'red'),\n",
    "                  rot=0,\n",
    "                  figsize= (16,10)\n",
    "                    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare the number of minutes users of each plan require each month. Plot a histogram.\n",
    "df_surf_calls.hist(bins=5)\n",
    "df_ultimate_calls.hist(bins=5)\n",
    "plt.title='Minutes Required'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The merged histograms\n",
    "df_surf_calls['call_duration'].plot(kind='hist', bins=15, title='Minutes Required', ylabel='Frequency', figsize=(15,8))\n",
    "df_ultimate_calls['call_duration'].plot(kind='hist', bins=15, alpha=0.3)\n",
    "\n",
    "plt.legend(['Surf', 'Ultimate'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Calculate the mean and the variable of the call duration to reason on whether users on the different plans have different behaviours for their calls.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and the variance of the monthly call duration, Surf plan\n",
    "print('mean')\n",
    "print(df_surf_calls.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_surf_calls.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and the variance of the monthly call duration, Ultimate plan\n",
    "print('mean')\n",
    "print(df_ultimate_calls.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_ultimate_calls.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a boxplot to visualize the distribution of the monthly call duration\n",
    "df_all_calls.plot(kind='box', title='Monthly Call Duration', figsize=(15,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# surf call durations\n",
    "surf_calls = df_surf_calls['call_duration'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ultimate call durations\n",
    "ultimate_calls = df_ultimate_calls['call_duration'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null hypothesis that the mean call durations for both plans is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses\n",
    "# Null hypothesis that the two means are the same\n",
    "alpha = 0.05  # critical statistical significance level\n",
    "# if the p-value is less than alpha, we reject the hypothesis\n",
    "\n",
    "results = st.ttest_ind(surf_calls, ultimate_calls)\n",
    "\n",
    "print('p-value: ', results.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print(\"We reject the null hypothesis, the average call durations differ\")\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The users of the two plans seem to have similar calling behavior, when considering call durations. In general, Surf plan customers and Ultimate plan customers have more messages 6 months each, out of the year. The mean call durations for both plans appeared to be similar, further visualized by the box plots, but we will test this hypothesis statistically. The Ultimate plan sees a greater variance in call duration compared to the Surf plan. This may be attributed to the outlier we see in the box plot of the Ultimate plan, yet the Surf plan has an outlier as well. Hypothesis testing suggests we cannot reject the null hypothesis that the mean call duration of both plans is similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visual of dataset we are working with\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare the number of messages users of each plan tend to send each month\n",
    "df_merged_msg = df_merged.groupby(['plan', 'month'])['num_messages'].mean()\n",
    "display(df_merged_msg.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of messages sent per month, Surf plan\n",
    "df_surf_msgs = df_merged_msg[1:13].reset_index('plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of messages sent per month, Ultimate plan\n",
    "df_ultimate_msgs = df_merged_msg.reset_index('plan').tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merged the dataset of the two plans side by side\n",
    "df_all_msgs = df_surf_msgs.merge(df_ultimate_msgs, on='month', how='outer')\n",
    "df_all_msgs.columns = ['plan_s', 'surf', 'plan_u', 'ultimate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying chart of the number of messages per plan, per month\n",
    "df_all_msgs.plot(kind='bar',\n",
    "                    title='Number of Messages',\n",
    "                  xlabel='Month',\n",
    "                  ylabel='Average Number of Messages',\n",
    "                  color=('blue', 'red'),\n",
    "                 rot=0,\n",
    "                  figsize= (16,10)\n",
    "                    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# showing statistical metrics\n",
    "print('mean')\n",
    "print(df_surf_msgs.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_surf_msgs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mean and variance of ultimate messages\n",
    "print('mean')\n",
    "print(df_ultimate_msgs.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_ultimate_msgs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distribution of surf messages\n",
    "df_surf_msgs.hist(bins=10)\n",
    "df_ultimate_msgs.hist(bins=10)\n",
    "plt.title='Messages'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf and ultimate messages\n",
    "df_surf_msgs['num_messages'].plot(kind='hist', bins=15, title='Number of Messages', ylabel='Frequency', figsize=(15,8))\n",
    "df_ultimate_msgs['num_messages'].plot(kind='hist', bins=15, alpha=0.5)\n",
    "\n",
    "plt.legend(['Surf', 'Ultimate'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a boxplot to visualize the distribution of the monthly call duration\n",
    "df_all_msgs.plot(kind='box', title='Monthly Number of Messages', figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# surf message values\n",
    "surf_msgs = df_surf_msgs['num_messages'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ultimate message values\n",
    "ultimate_msgs = df_ultimate_msgs['num_messages'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null hypothesis is the mean number of messages for the plans are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses\n",
    "# Null hypothesis that the two means are the same\n",
    "alpha = 0.05  # critical statistical significance level\n",
    "# if the p-value is less than alpha, we reject the hypothesis\n",
    "\n",
    "results = st.ttest_ind(surf_msgs, ultimate_msgs)\n",
    "\n",
    "print('p-value: ', results.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print(\"We reject the null hypothesis, the average number of messages differ\")\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of messages sent by customers of the Ultimate plan is consistently greater than that of Surf customers. The mean of the number of messages of the two plans appear different, however, we need to test this. Looking at the boxplot, we see the two plans are similar, and both have wide upper and lower bounds. Hypothesis testing suggests the average number of messages does not differ, contrary to our earlier thoughts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare the amount of internet traffic consumed by users per plan\n",
    "df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare the amount of internet traffic consumed by users per plan\n",
    "df_ints_traffic = df_merged.groupby(['plan', 'month'])['mb_used'].count()\n",
    "\n",
    "df_ints_traffic.columns = ['plan', 'month', 'internet_traffic']\n",
    "display(df_ints_traffic.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Internet traffic for Surf customers\n",
    "df_surf_ints_traffic = df_ints_traffic[1:13].reset_index('plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Internet traffic for Ultimate customers \n",
    "df_ultimate_ints_traffic = df_ints_traffic.reset_index('plan').tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# internet trffic for both Surf and Ultiate customers, merged on month\n",
    "df_all_ints_traffic = df_surf_ints_traffic.merge(df_ultimate_ints_traffic, on='month', how='outer')\n",
    "df_all_ints_traffic.columns = ['plan_s', 'surf', 'plan_u', 'ultimate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display chart on Internet traffic by plan, by month\n",
    "df_all_ints_traffic.plot(kind='bar',\n",
    "                    title='Internet Traffic Count',\n",
    "                  xlabel='Month',\n",
    "                  ylabel='Internet Traffic',\n",
    "                  color=('blue', 'red'),\n",
    "                 rot=0,\n",
    "                  figsize= (16,10)\n",
    "                    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surf internet traffic mean and variance\n",
    "print('mean')\n",
    "print(df_surf_ints_traffic.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_surf_ints_traffic.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ultimate internet traffic mean and variance\n",
    "print('mean')\n",
    "print(df_ultimate_ints_traffic.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_ultimate_ints_traffic.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display histogram of internet traffic per month, per plan\n",
    "df_surf_ints_traffic['mb_used'].plot(kind='hist', bins=15, title='Internet Traffic', ylabel='Frequency', figsize=(15,8))\n",
    "df_ultimate_ints_traffic['mb_used'].plot(kind='hist', bins=15, alpha=0.4)\n",
    "\n",
    "\n",
    "plt.legend(['Surf', 'Ultimate'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a boxplot to visualize the distribution of the monthly internet traffic\n",
    "df_all_ints_traffic.plot(kind='box', title='Monthly Internet Traffic', figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf traffic values\n",
    "surf_ints_traffic = df_surf_ints_traffic['mb_used'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ultimate traffic values\n",
    "ultimate_ints_traffic = df_ultimate_ints_traffic['mb_used'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null hypothesis is that the two mean data traffic numbers are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses\n",
    "alpha = 0.05  # critical statistical significance level\n",
    "# if the p-value is less than alpha, we reject the hypothesis\n",
    "\n",
    "results = st.ttest_ind(surf_ints_traffic, ultimate_ints_traffic)\n",
    "\n",
    "print('p-value: ', results.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print(\"We reject the null hypothesis, the average data traffic numbers differ\")\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Surf plan consistently sees more internet traffic than the Ultimate plan, with one exception. The mean internet traffic values appears to be quite different, further emphasized by the box plot. The upper and lower bounds of the Surf plan are wider than that of the Ultimate plan. This is made evident by the variance in the Surf data usage. Hypothesis testing further supports that the average traffic data numbers differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare average mb used per each plan per each distinct month. Plot a bar plat to visualize it.\n",
    "df_merged_ints = df_merged.groupby(['plan', 'month'])['mb_used'].mean()\n",
    "display(df_merged_ints.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data used per month in Surf plan\n",
    "df_surf_ints = df_merged_ints[1:13].reset_index('plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data used per month in Ultimate plan\n",
    "df_ultimate_ints = df_merged_ints.reset_index('plan').tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging of Surf and Ultimate data usage, per month\n",
    "df_all_ints = df_surf_ints.merge(df_ultimate_ints, on='month', how='outer')\n",
    "df_all_ints.columns = ['plan_s', 'surf', 'plan_u', 'ultimate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display visual of internet usage per month, per plan\n",
    "df_all_ints.plot(kind='bar',\n",
    "                    title='Megabytes Used',\n",
    "                  xlabel='Month',\n",
    "                  ylabel='Average Number of Megabytes',\n",
    "                  color=('blue', 'red'),\n",
    "                 rot=0,\n",
    "                  figsize= (16,10)\n",
    "                    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and variance of Surf data usage\n",
    "print('mean')\n",
    "print(df_surf_ints.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_surf_ints.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and variance of Ultimate data usage\n",
    "print('mean')\n",
    "print(df_ultimate_ints.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_ultimate_ints.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogras of Surf and Ultimate data usage\n",
    "df_surf_ints.hist(bins=10)\n",
    "df_ultimate_ints.hist(bins=10)\n",
    "plt.title='Megabytes'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged histogram of Surf and Ultimate dat usage\n",
    "df_surf_ints['mb_used'].plot(kind='hist', bins=5, title='Megabytes Used', ylabel='Frequency', figsize=(15,8))\n",
    "df_ultimate_ints['mb_used'].plot(kind='hist', bins=5, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.legend(['Surf', 'Ultimate'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a boxplot to visualize the distribution of the monthly call duration\n",
    "df_all_ints.plot(kind='box', title='Monthly Megabytes Used', figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf mb values\n",
    "surf_ints = df_surf_ints['mb_used'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# surf megabyte values\n",
    "ultimate_ints = df_ultimate_ints['mb_used'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null hypothesis that mean data usage is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses\n",
    "# Null hypothesis that the two means are the same\n",
    "alpha = 0.05  # critical statistical significance level\n",
    "# if the p-value is less than alpha, we reject the hypothesis\n",
    "\n",
    "results = st.ttest_ind(surf_ints, ultimate_ints)\n",
    "\n",
    "print('p-value: ', results.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print(\"We reject the null hypothesis, the average data usages differ\")\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ultimate plan customers consistently used more data than those of the Surf plan, with the exception of one month out of the year. The mean data usage of both plans appears to be quite similar, further emphasized by the box  plot. The Surf plan has an outlier on the lower side of data usage, and the upper and lower bounds are quite wide. The box plot of the Ultimate plan is tighter, with one outlier as well. Hypothesis testing suggests the mean data usage between plans is not different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically describe the revenue between the plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a monthly revenue column\n",
    "df_merged['monthly_revenue'] = df_merged.apply(revenue, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visual of the new column\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Greatest contributor to revenue\n",
    "df_merged[['num_calls', 'call_duration','month', 'mb_used', 'num_messages', 'monthly_revenue']] .corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# revenues of both plans\n",
    "df_merged_revs = df_merged.groupby(['plan', 'month'])['monthly_revenue'].mean()\n",
    "display(df_merged_revs.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate monthly revenue of Surf plan\n",
    "df_surf_revs = df_merged_revs[1:13].reset_index('plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate monthly revenue of Ultimate plan\n",
    "df_ultimate_revs = df_merged_revs.reset_index('plan').tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recombine revenue of both plans, per month\n",
    "df_all_revs = df_surf_revs.merge(df_ultimate_revs, on='month', how='outer')\n",
    "df_all_revs.columns = ['plan_s', 'surf', 'plan_u', 'ultimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot revenue per month, per plan\n",
    "df_all_revs.plot(kind='bar',\n",
    "                    title='Revenue',\n",
    "                  xlabel='Month',\n",
    "                  ylabel='Total Revenue',\n",
    "                  color=('blue', 'red'),\n",
    "                 rot=0,\n",
    "                  figsize= (16,10)\n",
    "                    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surf revenue mean and variance\n",
    "print('mean')\n",
    "print(df_surf_revs.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_surf_revs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surf revenue mean and variance\n",
    "print('mean')\n",
    "print(df_ultimate_revs.mean())\n",
    "print()\n",
    "print('variance')\n",
    "print(df_ultimate_revs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a boxplot to visualize the distribution of the monthly call duration\n",
    "df_all_revs.plot(kind='box', title='Monthly Revenue', figsize=(15,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ultimate plan consistently sees more revenue on a monthly basis. The mean revenues for the two plans appears to be different, but this will be further explored statistically. Looking at the box plot, we see the differences in the mean revenues. The Ultimate plan has a tighter range, while the Surf plan has a wider range and variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test statistical hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the hypothesis that the average revenues from users of the Ultimate and Surf calling plans differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting the revenues from the Surf plan\n",
    "surf_revs = df_surf_revs['monthly_revenue'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the revenues from the Ultimate Plan\n",
    "ultimate_revs = df_ultimate_revs['monthly_revenue'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null hypothesis is the mean revenues  of the Surf and Ultimate plans are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses\n",
    "# Null hypothesis that the two means are the same\n",
    "alpha = 0.05  # critical statistical significance level\n",
    "# if the p-value is less than alpha, we reject the hypothesis\n",
    "\n",
    "results = st.ttest_ind(surf_revs, ultimate_revs)\n",
    "\n",
    "print('p-value: ', results.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print(\"We reject the null hypothesis, the average revenues differ\")\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our earlier thoughts were wrong. Statistically, the mean revenues of both plans are different, but it is the Ultimate plan that brings in more revenue.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the hypothesis that the average revenue from users in the NY-NJ area is different from that of the users from the other regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Separating data based on user ID and city\n",
    "df_user_city = df_users[['user_id','city']]\n",
    "df_user_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adding data on plan and monthly revenue, merged by user ID\n",
    "df_all_cities = df_merged[['user_id', 'plan','monthly_revenue']].merge(df_user_city, on='user_id', how='left')\n",
    "df_all_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grouping the monthly revenue by city\n",
    "df_cities = df_all_cities.groupby('city')['monthly_revenue'].mean().reset_index()\n",
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sorting monthly revenue in descending order, by city\n",
    "df_cities_sorted = df_cities.sort_values(by='monthly_revenue', ascending=False)\n",
    "display(df_cities_sorted.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extracting rows based on the keywords that distinguish NY\n",
    "df_ny = df_all_cities[df_all_cities['city'].str.contains('New York-Newark-Jersey City, NY-NJ-PA MSA')]\n",
    "df_ny.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grouping NY revenue by user ID and monthly revenues\n",
    "df_ny_rev = df_ny.groupby('user_id')['monthly_revenue'].mean()\n",
    "df_ny_rev.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting the mean revenues from the NY data\n",
    "ny = df_ny_rev.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of NY revenue\n",
    "print('Mean: ')\n",
    "df_ny_rev.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviation of NY revenue\n",
    "print('Standard Deviation: ')\n",
    "df_ny_rev.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating cities data without NY, by index\n",
    "# Should see total rows drop from 73 to 72\n",
    "df_cities_2 = df_cities.drop(labels=43, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean revenue of all the other cities\n",
    "print('Mean :')\n",
    "df_cities_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of revenue of all the other cities\n",
    "print('Standard Deviation :')\n",
    "df_cities_2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#confirming NY is not in cities 2 data \n",
    "df_cities_2.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a boxplot to visualize the distribution of the monthly call duration\n",
    "df_ny_rev.plot(kind='box', title='NY Monthly Revenue', figsize=(15,8))\n",
    "df_cities_2.plot(kind='box', title='Other City Monthly Revenue',figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ny_rev.plot(kind='hist', title='NY Monthly Revenue', figsize=(15,8), color='darkgreen')\n",
    "df_cities_2.plot(kind='hist', title='Other Cities Monthly Revenue',figsize=(15,8), color='darkblue', alpha=.8, legend=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting mean revenues from cities 2 data \n",
    "cities_2 = df_cities_2['monthly_revenue'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null hypothesis that the mean revenue of Ny vs the other cities is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypotheses\n",
    "# Null hypothesis that the mean of NY is the same as the mean of the other cities\n",
    "alpha = 0.05  # critical statistical significance level\n",
    "# if the p-value is less than alpha, we reject the hypothesis\n",
    "\n",
    "results = st.ttest_ind(ny, cities_2)\n",
    "\n",
    "print('p-value: ', results.pvalue)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "    print(\"We reject the null hypothesis, the average revenues differ\")\n",
    "else:\n",
    "    print(\"We can't reject the null hypothesis\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After statistical testing, we can not reject the null hypothesis that the mean of NY revenue is similar the the mean revenue of all the other cities. This suggests that they are indeed similar. This finding is further supported by the box plots, and histograms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between revenue and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making a dataset of the customers plan and monthly revenue, based on age\n",
    "df_age_rev = df_users[['age', 'user_id']].merge(df_merged, on='user_id', how='outer')\n",
    "df_age= df_age_rev[['age', 'user_id', 'plan', 'monthly_revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting a count of the number of customers at each age \n",
    "df_customers = df_age.groupby('age')['age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting the distribution of customer ages, across both plans\n",
    "df_customers.plot(kind='bar', figsize=(20,6), ylabel='Age', title='Age of Customers', color='black', alpha=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grouping by ages and plans\n",
    "df_customer_plans = df_age.groupby(['age', 'plan'])['user_id'].count()\n",
    "df_customer_plans = pd.DataFrame(df_customer_plans).reset_index(level=1)\n",
    "df_customer_plans.columns = ['plan', 'customers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting all age groups with Surf plan\n",
    "df_surf_customers = df_customer_plans[df_customer_plans['plan'].str.contains('surf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting all age groups with Ultimate plan\n",
    "df_ultimate_customers = df_customer_plans[df_customer_plans['plan'].str.contains('ultimate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombining Surf and Ultimate customers, based on age\n",
    "df_plan_ages = df_surf_customers.merge(df_ultimate_customers, on='age', how='left')\n",
    "df_plan_ages.columns = ['plan_s', 'surf_customers', 'plan_u', 'ultimate_customers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Showing the distributon of plan choices, based on age\n",
    "df_plan_ages.plot(kind='bar', figsize=(20,8), ylabel='Number of Customers', xlabel='Age',\n",
    "                  title='Age of Customers', color=('blue', 'red'), alpha=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see most age groups prefer the Surf plan, with a few exceptions that prefer the Ultimate plan. We were expecting to see a pattern that suggests younger customers prefer the cheaper plan, yet the data does not suggest that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing revenue and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mean Revenue based on age\n",
    "age_rev_mean = df_age.groupby('age')['monthly_revenue'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total monthly revenue based on age\n",
    "age_rev_sum = df_age.groupby('age')['monthly_revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying total revenue, based on age\n",
    "age_rev_sum.plot(kind='bar', figsize=(20,8), ylabel='Total Revenue', xlabel='Age', title='Total Revenue', color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying mean revenue, based on age\n",
    "age_rev_mean.plot(kind='bar', figsize=(20,8), ylabel='Mean Revenue', xlabel='Age', title='Average Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that looking at total revenue based on age could be misleading, as we demonstrated the distribution of the number of customers in each age group earlier. Therefore, mean revenue would be better for making comparisons across age groups. We do not see any noticeable pattern in the data. We anticipated that younger customers would show a spike in revenue, due to their perceived lack of maturity. However, that was not the case. We only see spikes in the data with Ultimate plan customers in a few age groups. The age groups with the smallest mean revenue are 22, 35, and 63 year olds. Those with the highest revenue are 33, 42, and 71 year olds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data shows statistical differences in mean revenue among the two plans, as the Ultimate plan brings in more revenue. Our significance level was set to 5%, and our p value was much higher. In simpler words, we reject our null hypothesis that the mean revenues were similar. \n",
    "\n",
    "The data shows us that capital allocation to marketing the Ultimate plan would likely yield a better cash on cash return, not based on popularity, but on revenue. As the Surf plan is more popular, new customers should be lead to the Ultimate plan instead. We saw many Surf customers would experience overages on their plan. These would be the prime customer base to push towards the ultimate plan. \n",
    "\n",
    "We see that the mean revenue of customers in New York appears to be similar to that of all the other cities combined.  Yet, Honolulu, Albany, and Colorado Springs are the cities with the highest average revenue. A marketing push may also be a good idea in those areas, to further increase revenue, while also considering market saturation. We did not see a preference of plans of customers of different age groups, as most preferred the Surf plan. \n",
    "\n",
    "Overall, the Ultimate plan is not very popular. As such, maybe it would be beneficial to test a middle tier plan, in order to capture customers who may be dismayed by the gap in plan prices. Another method that would lead to increased revenue would be to slightly increase the overage fees on the Surf plan. Yet, a smart revenue strategy remains in rounding up minutes, and more substantially, rounding up data used to the nearest gigabyte. Data usage appears to be the largest contributor to revenue.\n",
    "\n",
    "Finally, Hypothesis testing suggests the mean of the call durations and number of messages were not different. On the other hand, internet traffic is different, when conducting statistical tests on the means."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 828,
    "start_time": "2021-11-16T09:21:11.304Z"
   },
   {
    "duration": 893,
    "start_time": "2021-11-16T09:21:17.728Z"
   },
   {
    "duration": 1150,
    "start_time": "2021-11-16T09:21:29.568Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:24:14.495Z"
   },
   {
    "duration": 120,
    "start_time": "2021-11-16T09:24:46.630Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:28:27.882Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:29:54.281Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:30:45.936Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:31:06.300Z"
   },
   {
    "duration": 113,
    "start_time": "2021-11-16T09:31:37.208Z"
   },
   {
    "duration": 143,
    "start_time": "2021-11-16T09:31:48.656Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-16T09:31:55.678Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:32:08.535Z"
   },
   {
    "duration": 111,
    "start_time": "2021-11-16T09:32:10.120Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:32:15.732Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:32:29.423Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:03:03.074Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:10:01.288Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:10:46.923Z"
   },
   {
    "duration": 121,
    "start_time": "2021-11-16T10:37:46.494Z"
   },
   {
    "duration": 125,
    "start_time": "2021-11-16T10:38:20.632Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T10:46:53.001Z"
   },
   {
    "duration": 110,
    "start_time": "2021-11-16T10:48:25.775Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:50:18.720Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T10:50:37.649Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-16T10:50:51.884Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:51:56.237Z"
   },
   {
    "duration": 101,
    "start_time": "2021-11-16T10:53:13.791Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:55:59.186Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:10.751Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.038Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.174Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T10:56:49.414Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.680Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:50.370Z"
   },
   {
    "duration": 114,
    "start_time": "2021-11-16T10:59:34.518Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:01:41.201Z"
   },
   {
    "duration": 116,
    "start_time": "2021-11-16T11:01:48.754Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:16.685Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:19.479Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:47.067Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:49.353Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:03:07.835Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:03:07.953Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T11:07:52.072Z"
   },
   {
    "duration": 187,
    "start_time": "2021-11-16T11:09:23.468Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:10:01.455Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:05.069Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:10:13.376Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:14.434Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:22.853Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:27:29.279Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:29:08.919Z"
   },
   {
    "duration": 118,
    "start_time": "2021-11-16T11:29:46.703Z"
   },
   {
    "duration": 437,
    "start_time": "2021-11-16T11:36:02.181Z"
   },
   {
    "duration": 157,
    "start_time": "2021-11-16T11:36:14.388Z"
   },
   {
    "duration": 207,
    "start_time": "2021-11-16T11:47:15.898Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:53:52.092Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:53:52.236Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:59:12.005Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T12:00:33.446Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T12:02:14.453Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T12:02:39.512Z"
   },
   {
    "duration": 106,
    "start_time": "2021-11-16T12:03:03.460Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:37:21.139Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:37:22.229Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:38:38.806Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:38:41.958Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:43:46.551Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:58:21.835Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:59:21.872Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:59:45.352Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:59:49.646Z"
   },
   {
    "duration": 159,
    "start_time": "2021-11-17T21:02:26.949Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:03:53.461Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:03:53.694Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:05:28.145Z"
   },
   {
    "duration": 116,
    "start_time": "2021-11-17T21:05:57.787Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:06:37.993Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:06:38.261Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:11:54.358Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:12:43.846Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:13:08.773Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:14:44.441Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:42.059Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:15:51.995Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:53.923Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:55.282Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:16:28.492Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:16:32.603Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:17:06.941Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-17T21:18:05.733Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:21:35.255Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:21:37.804Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:23:06.071Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:23:24.799Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:23:32.591Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-17T21:28:31.559Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:28:45.448Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:17.303Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:29.617Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:32.681Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:11.474Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:14.791Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:53.943Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:56.165Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:37:16.590Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:37:22.702Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:38:03.479Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:08.601Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:12.928Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:48.896Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-17T21:38:49.171Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:39:57.889Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:39:58.057Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:41:20.108Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:41:20.629Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:42:49.136Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:43:15.137Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:43:16.766Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:43:31.711Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:43:36.312Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:08.825Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:10.119Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:13.748Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:45:22.219Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:45:33.412Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-17T21:46:01.885Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:46:03.628Z"
   },
   {
    "duration": 107,
    "start_time": "2021-11-17T21:47:32.512Z"
   },
   {
    "duration": 103,
    "start_time": "2021-11-17T21:50:36.243Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:28:31.440Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:29:00.168Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:31:27.008Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-18T06:35:34.288Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-18T06:38:04.527Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.75px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4f2b0cfe12c109b58467a02dc33230d9e6228c23b43020d2941c37e2a7dfdd3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
